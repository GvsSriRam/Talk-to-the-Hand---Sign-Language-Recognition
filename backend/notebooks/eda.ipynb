{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719941063.398206 4480198 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2 Pro\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the MediaPipe Hands model\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "\n",
    "def get_landmarks(file_location):\n",
    "    # Read the image\n",
    "    image = cv2.imread(file_location)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and get the landmarks data\n",
    "    results = mp_hands.process(image_rgb)\n",
    "\n",
    "    # Extract the landmarks from the results\n",
    "    landmarks = results.multi_hand_landmarks\n",
    "    \n",
    "    # Convert the landmarks to a numpy array\n",
    "    if landmarks:\n",
    "        landmarks_np = np.array([[landmark.x, landmark.y, landmark.z] for landmark in landmarks[0].landmark])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return landmarks_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1719941063.414890 4480522 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1719941063.421870 4480522 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(223075, 29)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of subfolders and files in the given \n",
    "files = []\n",
    "folders = []\n",
    "def count_files(path='.'):\n",
    "    global file_count, folder_count\n",
    "    with os.scandir(path) as entries:\n",
    "        \n",
    "        for entry in entries:\n",
    "            # print(entry.path)\n",
    "            # print(curr_label)\n",
    "            if entry.is_file():\n",
    "                files.append(entry.path)\n",
    "            elif entry.is_dir():\n",
    "                folders.append(entry.path)\n",
    "                count_files(entry.path)\n",
    "        \n",
    "    return files, folders\n",
    "\n",
    "count_files(\"/Users/gvssriram/Desktop/projects-internship/MathNoteX/sign/ASL_Alphabet_Dataset/asl_alphabet_train\")\n",
    "\n",
    "len(set(files)), len(set(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1719360603.128705 9646481 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1719360603.134692 9646481 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/Users/gvssriram/anaconda3/envs/math_note_x/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "U\n",
      "I\n",
      "N\n",
      "G\n",
      "Z\n",
      "T\n",
      "S\n",
      "A\n",
      "F\n",
      "O\n",
      "H\n",
      "del\n",
      "nothing\n",
      "space\n",
      "M\n",
      "J\n",
      "C\n",
      "D\n",
      "V\n",
      "Q\n",
      "X\n",
      "E\n",
      "B\n",
      "K\n",
      "L\n",
      "Y\n",
      "P\n",
      "W\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list to store the landmarks\n",
    "landmarks_list = []\n",
    "        \n",
    "# Initialize the list to store the labels\n",
    "labels = []\n",
    "\n",
    "global curr_label\n",
    "curr_label = \"\"\n",
    "\n",
    "def getLandmarksAndLabels(path='.'):\n",
    "    global curr_label\n",
    "    with os.scandir(path) as entries:\n",
    "        \n",
    "        for entry in entries:\n",
    "            # print(entry.path)\n",
    "            # print(curr_label)\n",
    "            if entry.is_file():\n",
    "                landmarks = get_landmarks(entry.path)\n",
    "                # print(landmarks)\n",
    "                if landmarks is not None:\n",
    "                    landmarks_list.append(landmarks)\n",
    "                    labels.append(curr_label)\n",
    "                # else:\n",
    "                #     print(\"No landmarks found\")\n",
    "            elif entry.is_dir():\n",
    "                curr_label = entry.name\n",
    "                print(curr_label)\n",
    "                getLandmarksAndLabels(entry.path)\n",
    "        \n",
    "    return landmarks_list, labels\n",
    "\n",
    "x_train, y_train = getLandmarksAndLabels(\"/Users/gvssriram/Desktop/projects-internship/MathNoteX/sign/ASL_Alphabet_Dataset/asl_alphabet_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, numpy.ndarray, str)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(y_train), type(x_train[0]), type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# convert the list to numpy array\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((169090, 21, 3), (169090,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../data/ASL_Alphabet_Dataset_Processed/x_train.npy', x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../data/ASL_Alphabet_Dataset_Processed/y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169090, 63)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape x_train\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../data/ASL_Alphabet_Dataset_Processed/x_train_flat.npy', x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed numpy image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Load numpy arrays\n",
    "x_train = np.load('../data/ASL_Alphabet_Dataset_Processed/x_train.npy')\n",
    "y_train = np.load('../data/ASL_Alphabet_Dataset_Processed/y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((169090, 21, 3), (169090,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5.15921772e-01,  7.92883813e-01,  4.68830564e-07],\n",
       "        [ 5.61473846e-01,  7.50161648e-01, -2.74555814e-02],\n",
       "        [ 5.77734768e-01,  6.88524961e-01, -4.12738435e-02],\n",
       "        ...,\n",
       "        [ 4.53955889e-01,  6.46603763e-01, -9.78934020e-02],\n",
       "        [ 4.90068585e-01,  6.74939871e-01, -1.07148461e-01],\n",
       "        [ 5.13166964e-01,  7.01320827e-01, -1.07620858e-01]],\n",
       "\n",
       "       [[ 5.05461454e-01,  8.36323082e-01,  1.18730497e-06],\n",
       "        [ 4.40506786e-01,  7.34651744e-01, -7.65210986e-02],\n",
       "        [ 4.25234973e-01,  5.97333670e-01, -9.95539799e-02],\n",
       "        ...,\n",
       "        [ 6.71594977e-01,  4.91894424e-01, -9.87732336e-02],\n",
       "        [ 6.45163357e-01,  5.66112816e-01, -1.00976720e-01],\n",
       "        [ 6.21084809e-01,  6.32574558e-01, -7.91223496e-02]],\n",
       "\n",
       "       [[ 7.31024981e-01,  8.74174833e-01,  2.61961304e-07],\n",
       "        [ 6.56271577e-01,  7.75128603e-01, -1.16133709e-02],\n",
       "        [ 6.35274231e-01,  6.68298721e-01, -1.62141919e-02],\n",
       "        ...,\n",
       "        [ 7.70584047e-01,  6.44464433e-01, -2.23915782e-02],\n",
       "        [ 7.34974027e-01,  6.89780831e-01, -1.33151729e-02],\n",
       "        [ 7.27163613e-01,  7.23066986e-01,  3.02314386e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 5.29827952e-01,  8.87458146e-01,  2.05605465e-06],\n",
       "        [ 6.08404219e-01,  8.12869847e-01, -1.16211742e-01],\n",
       "        [ 6.02727234e-01,  6.57908618e-01, -1.37231961e-01],\n",
       "        ...,\n",
       "        [ 3.47336233e-01,  5.11903465e-01, -1.12499282e-01],\n",
       "        [ 3.86267304e-01,  5.53781271e-01, -1.38561159e-01],\n",
       "        [ 4.12707359e-01,  6.19161129e-01, -1.44809395e-01]],\n",
       "\n",
       "       [[ 4.57049340e-01,  9.73257065e-01,  1.48334743e-06],\n",
       "        [ 5.69243491e-01,  9.14907157e-01, -8.67527872e-02],\n",
       "        [ 6.34918153e-01,  7.77601957e-01, -1.17056362e-01],\n",
       "        ...,\n",
       "        [ 3.88584197e-01,  5.59023499e-01, -1.75894409e-01],\n",
       "        [ 4.08882260e-01,  6.50428951e-01, -2.01585218e-01],\n",
       "        [ 4.19892669e-01,  7.33034611e-01, -2.07789540e-01]],\n",
       "\n",
       "       [[ 2.11173669e-01,  8.20506573e-01,  9.64784476e-07],\n",
       "        [ 2.81329155e-01,  7.98836529e-01, -7.51566961e-02],\n",
       "        [ 3.15608829e-01,  7.05221891e-01, -9.78051573e-02],\n",
       "        ...,\n",
       "        [ 1.51126966e-01,  4.97285753e-01, -1.01646930e-01],\n",
       "        [ 1.52351454e-01,  5.42399049e-01, -1.13477342e-01],\n",
       "        [ 1.53848737e-01,  5.93634784e-01, -1.12887859e-01]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04555207, -0.04272217, -0.02745605],\n",
       "        [ 0.061813  , -0.10435885, -0.04127431],\n",
       "        [ 0.02810705, -0.13061208, -0.05686834],\n",
       "        ...,\n",
       "        [-0.06196588, -0.14628005, -0.09789387],\n",
       "        [-0.02585319, -0.11794394, -0.10714893],\n",
       "        [-0.00275481, -0.09156299, -0.10762133]],\n",
       "\n",
       "       [[-0.06495467, -0.10167134, -0.07652229],\n",
       "        [-0.08022648, -0.23898941, -0.09955517],\n",
       "        [-0.01976028, -0.35343987, -0.12149395],\n",
       "        ...,\n",
       "        [ 0.16613352, -0.34442866, -0.09877442],\n",
       "        [ 0.1397019 , -0.27021027, -0.10097791],\n",
       "        [ 0.11562335, -0.20374852, -0.07912354]],\n",
       "\n",
       "       [[-0.0747534 , -0.09904623, -0.01161363],\n",
       "        [-0.09575075, -0.20587611, -0.01621445],\n",
       "        [-0.06241727, -0.27738518, -0.03013196],\n",
       "        ...,\n",
       "        [ 0.03955907, -0.2297104 , -0.02239184],\n",
       "        [ 0.00394905, -0.184394  , -0.01331543],\n",
       "        [-0.00386137, -0.15110785,  0.00302288]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.07857627, -0.0745883 , -0.1162138 ],\n",
       "        [ 0.07289928, -0.22954953, -0.13723402],\n",
       "        [-0.05775815, -0.33805758, -0.13067882],\n",
       "        ...,\n",
       "        [-0.18249172, -0.37555468, -0.11250134],\n",
       "        [-0.14356065, -0.33367687, -0.13856322],\n",
       "        [-0.11712059, -0.26829702, -0.14481145]],\n",
       "\n",
       "       [[ 0.11219415, -0.05834991, -0.08675427],\n",
       "        [ 0.17786881, -0.19565511, -0.11705785],\n",
       "        [ 0.06320146, -0.29665112, -0.13271963],\n",
       "        ...,\n",
       "        [-0.06846514, -0.41423357, -0.17589589],\n",
       "        [-0.04816708, -0.32282811, -0.2015867 ],\n",
       "        [-0.03715667, -0.24022245, -0.20779102]],\n",
       "\n",
       "       [[ 0.07015549, -0.02167004, -0.07515766],\n",
       "        [ 0.10443516, -0.11528468, -0.09780612],\n",
       "        [ 0.03092328, -0.20221168, -0.10610279],\n",
       "        ...,\n",
       "        [-0.0600467 , -0.32322082, -0.10164789],\n",
       "        [-0.05882221, -0.27810752, -0.11347831],\n",
       "        [-0.05732493, -0.22687179, -0.11288882]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each row has 21 points of landmarks (x,y,z). Compute the relative positions between each point and 0th point\n",
    "# Compute the relative positions between each point and 0th point\n",
    "def get_relative_positions(x):\n",
    "    relative_positions = []\n",
    "    for i in range(1, len(x)):\n",
    "        relative_positions.append(x[i] - x[0])\n",
    "    return np.array(relative_positions)\n",
    "\n",
    "# Compute the relative positions between each point and 0th point\n",
    "x_train_relative = np.apply_along_axis(get_relative_positions, 1, x_train)\n",
    "x_train_relative.shape\n",
    "\n",
    "np.save('../data/ASL_Alphabet_Dataset_Processed/x_train_relative.npy', x_train_relative)\n",
    "\n",
    "# Load numpy arrays\n",
    "x_train_relative = np.load('../data/ASL_Alphabet_Dataset_Processed/x_train_relative.npy')\n",
    "\n",
    "x_train_relative.shape\n",
    "\n",
    "x_train_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169090, 20, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_relative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# one hot encode the labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_train = encoder.fit_transform(y_train.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169090, 29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169090, 60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_relative = x_train_relative.reshape(x_train_relative.shape[0], x_train_relative.shape[1]*x_train_relative.shape[2])\n",
    "x_train_relative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvssriram/anaconda3/envs/sign_lang_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">957</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │           \u001b[38;5;34m957\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,997</span> (78.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,997\u001b[0m (78.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,549</span> (76.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,549\u001b[0m (76.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 836us/step - categorical_accuracy: 0.4676 - loss: 2.3455 - val_categorical_accuracy: 0.0286 - val_loss: 10.9783 - learning_rate: 0.0050\n",
      "Epoch 2/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 812us/step - categorical_accuracy: 0.5840 - loss: 1.7333 - val_categorical_accuracy: 0.0259 - val_loss: 12.0989 - learning_rate: 0.0050\n",
      "Epoch 3/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 789us/step - categorical_accuracy: 0.5860 - loss: 1.7120 - val_categorical_accuracy: 0.0275 - val_loss: 14.8708 - learning_rate: 0.0050\n",
      "Epoch 4/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 778us/step - categorical_accuracy: 0.5810 - loss: 1.6994 - val_categorical_accuracy: 0.0298 - val_loss: 17.4214 - learning_rate: 0.0050\n",
      "Epoch 5/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 772us/step - categorical_accuracy: 0.6659 - loss: 1.3594 - val_categorical_accuracy: 0.0296 - val_loss: 18.7067 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 784us/step - categorical_accuracy: 0.7032 - loss: 1.1495 - val_categorical_accuracy: 0.0294 - val_loss: 19.1266 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 802us/step - categorical_accuracy: 0.7157 - loss: 1.1034 - val_categorical_accuracy: 0.0290 - val_loss: 19.3479 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 792us/step - categorical_accuracy: 0.7407 - loss: 1.0255 - val_categorical_accuracy: 0.0298 - val_loss: 19.6321 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 838us/step - categorical_accuracy: 0.7464 - loss: 0.9942 - val_categorical_accuracy: 0.0296 - val_loss: 19.8332 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 832us/step - categorical_accuracy: 0.7491 - loss: 0.9869 - val_categorical_accuracy: 0.0292 - val_loss: 19.8430 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m4228/4228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 795us/step - categorical_accuracy: 0.7513 - loss: 0.9754 - val_categorical_accuracy: 0.0297 - val_loss: 20.0790 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Create a classification model using tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(x_train_relative.shape[1],), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(29, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "metrics = []\n",
    "metrics.append(\"categorical_accuracy\")\n",
    "\n",
    "# callbacks\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint = ModelCheckpoint(filepath='../models/ckpts/asl_alphabet_model.keras', monitor='val_loss', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.0001)\n",
    "tensorboard = TensorBoard(log_dir='../tflogs')\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr, tensorboard]\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x_train_relative, y_train, epochs=100, validation_split=0.2, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5285/5285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 283us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_train_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7921494e-06, 6.5810517e-03, 1.4306526e-04, 1.4486490e-04,\n",
       "       1.8309147e-04, 7.0842635e-04, 4.2900341e-05, 3.5214867e-03,\n",
       "       1.5406873e-07, 3.2711628e-06, 1.6626106e-09, 1.7903333e-09,\n",
       "       1.3582588e-05, 6.6933762e-06, 2.2234150e-05, 1.7186821e-09,\n",
       "       2.2016544e-05, 1.9907267e-01, 1.0864065e-04, 1.1295699e-04,\n",
       "       5.4506183e-01, 2.4385253e-01, 1.8903989e-09, 3.1724933e-04,\n",
       "       1.8134144e-09, 5.1291594e-05, 5.8289618e-07, 3.4878096e-07,\n",
       "       2.6169939e-05], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 17, 17, ..., 20, 20, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 17, 17, ..., 22, 22, 22])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "y_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7038618487196168"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy_score(y_train_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83      6087\n",
      "           1       0.78      0.98      0.87      6931\n",
      "           2       0.93      0.92      0.92      5740\n",
      "           3       0.51      0.85      0.63      6890\n",
      "           4       0.94      0.92      0.93      6240\n",
      "           5       0.95      0.96      0.96      7514\n",
      "           6       0.83      0.93      0.88      6334\n",
      "           7       0.74      0.92      0.82      6407\n",
      "           8       0.67      0.90      0.77      6700\n",
      "           9       0.65      0.89      0.75      5767\n",
      "          10       0.00      0.00      0.00      7097\n",
      "          11       0.00      0.00      0.00      7294\n",
      "          12       0.65      0.72      0.68      4123\n",
      "          13       0.70      0.51      0.59      3579\n",
      "          14       0.81      0.94      0.87      6254\n",
      "          15       0.00      0.00      0.00      5224\n",
      "          16       0.56      0.96      0.71      5223\n",
      "          17       0.61      0.86      0.71      6993\n",
      "          18       0.80      0.93      0.86      6250\n",
      "          19       0.71      0.76      0.74      6407\n",
      "          20       0.33      0.64      0.44      6547\n",
      "          21       0.63      0.87      0.73      6411\n",
      "          22       0.00      0.00      0.00      6655\n",
      "          23       0.76      0.89      0.82      6342\n",
      "          24       0.00      0.00      0.00      6518\n",
      "          25       0.84      0.79      0.82      6318\n",
      "          26       0.90      0.94      0.92      3577\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.87      0.93      0.90      3665\n",
      "\n",
      "    accuracy                           0.70    169090\n",
      "   macro avg       0.58      0.69      0.63    169090\n",
      "weighted avg       0.59      0.70      0.64    169090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvssriram/anaconda3/envs/sign_lang_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/gvssriram/anaconda3/envs/sign_lang_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/gvssriram/anaconda3/envs/sign_lang_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the MediaPipe Hands model\n",
    "mp_hands.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math_note_x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
